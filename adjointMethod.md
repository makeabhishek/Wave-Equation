# Adjoint state method
To obtain the value of the adjoint state utilizing the boundary condition (BC) involves a multi-step process that has a significant impact on the final outcome. It is crucial to keep in mind that the key to obtain the adjoint state is to derive the adjoint equation and apply the appropriate initial and boundary conditions. To begin with, it is essential to derive the adjoint equation from the forward problem and apply the appropriate boundary conditions for deriving the adjoint state. Here are the steps that need to be followed:

### Derive the adjoint equation: 
Starting from the forward problem, which could be the wave equation or any other relevant problem, the adjoint equation can be derived. This is achieved by taking the derivative of the forward problem concerning the model parameters and subsequently applying the adjoint operator. It is crucial to note that the adjoint equation possesses a structure similar to the forward problem. The only difference is that the time is reversed, and a new source term, which is derived from the misfit function, is added.

### Define the initial condition for the adjoint equation: 
The initial condition for the adjoint equation is typically the zero state. This means that the adjoint state is zero at the final time, and this condition ensures causality. The zero state corresponds to the fact that the adjoint state is generated by the mismatch between the observed and modelled data.

### Apply the boundary conditions: 
In the same manner as the forward problem, the adjoint equation requires boundary conditions to be well-posed. It is essential to base the boundary conditions for the adjoint equation on the corresponding conditions of the forward problem. For instance, if the forward problem has Dirichlet or Neumann boundary conditions, the adjoint equation will also have the same type of boundary conditions applied at the same locations.

### Solve the adjoint equation: 
With the adjoint equation, initial condition, and boundary conditions properly defined, the next step involves solving the adjoint equation. This can be accomplished through various numerical methods such as finite differences, finite elements, or spectral methods. Solving the adjoint equation enables the derivation of the adjoint state, which can be further used to compute the gradient of the objective function concerning the model parameters.

# Taylor Series
Taylor's theorem (actually discovered first by Gregory) states that any function satisfying certain conditions can be expressed as a Taylor series. Taylor series is a series expansion of a function about a point. \
A one-dimensional Taylor series is an expansion of a real function $f(x)$ about a point $x=a$ is given by \
$f(x) = f(a) + \frac{f'(a)}{2\!}(x-a)^2 + + \frac{f''(a)}{3\!}(x-a)^3 + \cdot \cdot \cdot + \frac{f^{n}(a)}{n\!}(x-a)^n +  \cdot \cdot \cdot$ \
If $a=0$, the expansion is known as a **Maclaurin series**. \

A Taylor series of a real function in two variables $f(x,y)$ is given by \
$f(x + \Delta x, y + \Delta y) = f(x,y) + [f\_x (x,y)\Delta x + f_y\ (x,y) \Delta y] + \frac{1}{2\!} [(\Delta x)^2 f\_{xx} (x,y) + 2 \Delta x \Delta y f\_{xy} (x,y) + (\Delta y)^2 f_{yy} (x,y)] +$ \
$\frac{1}{3\!}[(\Delta x)^3 f\_{xxx} (x,y) + 3 (\Delta x)^2 \Delta y f\_{xxy}(x,y) + 3 \Delta x (\Delta y)^2 f\_{xyy}(x,y) + (\Delta y)^3 f\_{yyy}(x,y)] + \cdot \cdot \cdot$ \

# What is the difference between a gradient and a derivative?
They are pretty much the same thing. The difference comes from the number of dimensions of your function.

In one variable functions you only need the derivative to know how a function is changing. In multivariable functions there are multiple directions that a function can change in and therefore it is no longer sufficient to have only 1 derivative. But you can define a new idea, the gradient to describe how the function changes in multiple dimensions. The gradient is just a vector with the functionâ€™s partial derivatives for components. For instance $grad(f(x,y))=$ $\nabla (f(x,y)) = \frac{df(x,y)}{dx}, \frac{df(x,y)}{dy}$. 

In a rectangular reference frame, gradient is a vector field, whose three Cartesian components are partial derivatives of a scalar field with respect to cartesian components of location. Gradient of the vector field is the second-order tensor, for example, gradient of velocity in fluid mechanics. Gradients of strain tensor and stress tensor are third-order tensors

# Gradient, directional derivative, the derivative, the Jacobian, the total differential, the directional derivative, the partial derivative, and Frechet derivative, and the Hessian.
https://math.stackexchange.com/questions/1067149/what-is-difference-between-all-of-these-derivatives 

# Adjoint-state method from the perturbation theory
The modeling schem 
$u=Am$ \
$\rightarrow 0 = F(m) = u-Am$ \
The objective function $J(m) = h(u) = \frac{1}{2} ||u-d||_c^2$ \
Initial: model paramter 'm', state variable 'u', objective funtion 'J' \
Perturbed: $m +\delta m$, $u +\delta u$, $J +\delta J$ \
$0 = F(u +\delta u, m +\delta m)$ \
Expanding, \
$\= F(u, m) + \frac{\partial F}{\partial u}\delta u + \frac{\partial F}{\partial m}\delta m $ \
Note that \
$F(u, m)=0 \rightarrow \frac{\partial F}{\partial u}\delta u =- \frac{\partial F}{\partial m}\delta m $ \
In the linear case: $F(u, m)=u-Am$ \
$\delta u = A\delta m$ \




